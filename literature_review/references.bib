######################### computer vision refrences ######################

@article{originalcnn,
      author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
      title = {Backpropagation Applied to Handwritten Zip Code Recognition},
      journal = {Neural Computation},
      volume = {1},
      number = {4},
      pages = {541-551},
      year = {1989},
      doi = {10.1162/neco.1989.1.4.541},
      URL = { https://doi.org/10.1162/neco.1989.1.4.541},
      eprint = { https://doi.org/10.1162/neco.1989.1.4.541},
      abstract = { The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification. }
}

@misc{understanding-cnn,
      title={Visualizing and Understanding Convolutional Networks}, 
      author={Matthew D Zeiler and Rob Fergus},
      year={2013},
      eprint={1311.2901},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{alexnet,
      author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
      booktitle = {Advances in Neural Information Processing Systems},
      editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
      pages = {1097--1105},
      publisher = {Curran Associates, Inc.},
      title = {ImageNet Classification with Deep Convolutional Neural Networks},
      url = {https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
      volume = {25},
      year = {2012}
}

@misc{vgg,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{inception,
      title={Going Deeper with Convolutions}, 
      author={Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke and Andrew Rabinovich},
      year={2014},
      eprint={1409.4842},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{inceptionv2-3,
      title={Rethinking the Inception Architecture for Computer Vision}, 
      author={Christian Szegedy and Vincent Vanhoucke and Sergey Ioffe and Jonathon Shlens and Zbigniew Wojna},
      year={2015},
      eprint={1512.00567},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{resnet,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{inceptionv4,
      title={Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning}, 
      author={Christian Szegedy and Sergey Ioffe and Vincent Vanhoucke and Alex Alemi},
      year={2016},
      eprint={1602.07261},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{wideresnet,
      title={Wide Residual Networks}, 
      author={Sergey Zagoruyko and Nikos Komodakis},
      year={2017},
      eprint={1605.07146},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{resnext,
      title={Aggregated Residual Transformations for Deep Neural Networks}, 
      author={Saining Xie and Ross Girshick and Piotr Dollár and Zhuowen Tu and Kaiming He},
      year={2017},
      eprint={1611.05431},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{effnet,
      title={EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks}, 
      author={Mingxing Tan and Quoc V. Le},
      year={2020},
      eprint={1905.11946},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{image-attention,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2020},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

######################### FER refrences ######################

@misc{emotionnet-nano,
      title={EmotionNet Nano: An Efficient Deep Convolutional Neural Network Design for Real-time Facial Expression Recognition}, 
      author={James Ren Hou Lee and Linda Wang and Alexander Wong},
      year={2020},
      eprint={2006.15759},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@INPROCEEDINGS {ck+,
      author = {P. Lucey and J. F. Cohn and T. Kanade and J. Saragih and Z. Ambadar and I. Matthews},
      booktitle = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops)},
      title = {The Extended Cohn-Kanade Dataset (CK+): A complete dataset for action unit and emotion-specified expression},
      year = {2010},
      volume = {},
      issn = {2160-7508},
      pages = {94-101},
      keywords = {databases;gold;active appearance model;support vector machines;support vector machine classification;face detection;testing;performance evaluation;measurement;code standards},
      doi = {10.1109/CVPRW.2010.5543262},
      url = {https://doi.ieeecomputersociety.org/10.1109/CVPRW.2010.5543262},
      publisher = {IEEE Computer Society},
      address = {Los Alamitos, CA, USA},
      month = {jun}
}

@misc{fan,
      title={Frame attention networks for facial expression recognition in videos}, 
      author={Debin Meng and Xiaojiang Peng and Kai Wang and Yu Qiao},
      year={2019},
      eprint={1907.00193},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{c3d,
      author = {Fan, Yin and Lu, Xiangju and Li, Dian and Liu, Yuanliu},
      year = {2016},
      month = {11},
      pages = {},
      title = {Video-based emotion recognition using CNN-RNN and C3D hybrid networks},
      doi = {10.1145/2993148.2997632}
}


######################### psychology refrences ######################

@book{Darwin_book,
      author     = {Darwin, Charles},
      note       = {The original was published 1898 by Appleton, New York. Reprinted 1965 by the University of Chicago Press, Chicago and London,},
      title      = {The Expression of the Emotions in Man and Animals},
      year       = {1872},
      iso_code   = {tur},
      olac_field = {typology; general_linguistics},
      wals_code  = {tur}
}

@book{barrett2017emotions,
      title={How Emotions Are Made: The Secret Life of the Brain},
      author={Barrett, L.F.},
      isbn={9780544129962},
      lccn={2017004323},
      url={https://books.google.co.il/books?id=hN8MBgAAQBAJ},
      year={2017},
      publisher={HMH Books}
}

@inproceedings{2d_emotions_figure,
      author = {Hussain, Sazzad and AlZoubi, Omar and Calvo, Rafael and D'Mello, Sidney},
      year = {2011},
      month = {06},
      pages = {131-138},
      title = {Affect Detection from Multichannel Physiology during Learning Sessions with AutoTutor},
      isbn = {978-3-642-21868-2},
      doi = {10.1007/978-3-642-21869-9_19}
}

@inproceedings{3d_emotions_figure,
      author = {Buechel, Sven and Hahn, Udo},
      year = {2016},
      month = {08},
      pages = {},
      title = {Emotion Analysis as a Regression Problem — Dimensional Models and Their Implications on Emotion Representation and Metrical Evaluation},
      doi = {10.3233/978-1-61499-672-9-1114}
}

@Book{APA_Dictionary,
    publisher = {American Psychological Association},
    title = {{APA dictionary}},
    year = {2020},
}

@Book{MW-Dictionary,
    publisher = {Merriam Webster},
    title = {{MW dictionary}},
    year = {2020},
}

@article{human_computer_interaction,
      author = {Brave, Scott and Nass, Clifford},
      year = {2002},
      month = {01},
      pages = {},
      title = {Emotion in Human–Computer Interaction},
      isbn = {978-1-4200-8881-6},
      journal = {The Human-Computer Interaction Handbook: Fundamentals, Evolving Technologies and Emerging Applications},
      doi = {10.1201/b10368-6}
}

@article{VAD_model,
      author = {Russell, James and Mehrabian, Albert},
      year = {1977},
      month = {09},
      pages = {273-294},
      title = {Evidence for a Three-Factor Theory of Emotions},
      volume = {11},
      journal = {Journal of Research in Personality},
      doi = {10.1016/0092-6566(77)90037-X}
}

@article{VA_model,
      author = { Lisa Feldman   Barrett },
      title = {Discrete Emotions or Dimensions? The Role of Valence Focus and Arousal Focus},
      journal = {Cognition and Emotion},
      volume = {12},
      number = {4},
      pages = {579-599},
      year  = {1998},
      publisher = {Routledge},
      doi = {10.1080/026999398379574},
      URL = {https://doi.org/10.1080/026999398379574},
      eprint = {https://doi.org/10.1080/026999398379574}
}

@article{Ekman_Theory,
	author = { Paul   Ekman },
	title = {An argument for basic emotions},
	journal = {Cognition and Emotion},
	volume = {6},
	number = {3-4},
	pages = {169-200},
	year  = {1992},
	publisher = {Routledge},
	doi = {10.1080/02699939208411068},
	URL = {https://doi.org/10.1080/02699939208411068},
	eprint = {https://doi.org/10.1080/02699939208411068}
}

@article{WG-Theory,
      author = {Graham, Sandra and Weiner, Bernard},
      year = {1986},
      month = {06},
      pages = {152-179},
      title = {From an Attributional Theory of Emotion to Developmental Psychology: A Round-Trip Ticket?},
      volume = {4},
      journal = {Social Cognition},
      doi = {10.1521/soco.1986.4.2.152}
}

######################### psychology refrences ######################

@book{affective_computing_book,
  title={Affective Computing},
  author={Picard, R.W.},
  isbn={9780262661157},
  lccn={97033285},
  series={Inteligencia artificial},
  url={https://books.google.co.il/books?id=GaVncRTcb1gC},
  year={2000},
  publisher={MIT Press}
}

@online{AutoEmotive,
  author = {{Hernandez J., McDuff D., Benavides X., Amores J., Maes P., and Picard R. W.}},
  title = {AutoEmotive: Bringing Empathy to the Driving Experience to Manage Stress},
  year = 2014,
  url = {https://www.media.mit.edu/publications/autoemotive-bringing-empathy-to-the-driving-experience-to-manage-stress},
  urldate = {2014-06-21}
}

######################### ml refrences ######################

@article{machine_learning_classification_algorithms,
      author = {Kotsiantis, Sotiris},
      year = {2007},
      month = {10},
      pages = {},
      title = {Supervised Machine Learning: A Review of Classification Techniques},
      volume = {31},
      journal = {Informatica (Ljubljana)}
}

@article{CC01a,
      author = {Chang, Chih-Chung and Lin, Chih-Jen},
      title = {{LIBSVM}: A library for support vector machines},
      journal = {ACM Transactions on Intelligent Systems and Technology},
      volume = {2},
      issue = {3},
      year = {2011},
      pages = {27:1--27:27},
      note = {Software available at \url{http://www.csie.ntu.edu.tw/~cjlin/libsvm}}
}

@inproceedings{nnbook1995,
  title={Neural Network Design},
  author={Martin T. Hagan and Howard B. Demuth and Mark Beale},
  year={1995}
}

@misc{gru,
      title={Gate-Variants of Gated Recurrent Unit (GRU) Neural Networks}, 
      author={Rahul Dey and Fathi M. Salem},
      year={2017},
      eprint={1701.05923},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

@article{lstm,
      author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
      year = {1997},
      month = {12},
      pages = {1735-80},
      title = {Long Short-term Memory},
      volume = {9},
      journal = {Neural computation},
      doi = {10.1162/neco.1997.9.8.1735}
}


@misc{vanishing-gradients,
      title={On the difficulty of training Recurrent Neural Networks}, 
      author={Razvan Pascanu and Tomas Mikolov and Yoshua Bengio},
      year={2013},
      eprint={1211.5063},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

######################### related work keyboard + mouse ################

@article{Zimmermann,
      author = {Zimmermann, Philippe and Guttormsen, Sissel and Danuser, Brigitta and Gomez, Patrick},
      year = {2003},
      month = {02},
      pages = {539-51},
      title = {Affective Computing—A Rationale for Measuring Mood With Mouse and Keyboard},
      volume = {9},
      journal = {International journal of occupational safety and ergonomics : JOSE},
      doi = {10.1080/10803548.2003.11076589}
}

@article{Khanna,
      author = {Khanna, Preeti and Mukundan, Sasikumar},
      year = {2010},
      month = {12},
      pages = {},
      title = {Recognising Emotions from Keyboard Stroke Pattern},
      volume = {11},
      journal = {International Journal of Computer Applications},
      doi = {10.5120/1614-2170}
}

@article{An_Evaluation_Of_Mouse_And_Keyboard_Interaction,
      title = "An Evaluation of Mouse and Keyboard Interaction Indicators towards Non-intrusive and Low Cost Affective Modeling in an Educational Context",
      journal = "Procedia Computer Science",
      volume = "35",
      pages = "691 - 700",
      year = "2014",
      issn = "1877-0509",
      doi = "https://doi.org/10.1016/j.procs.2014.08.151",
      url = "http://www.sciencedirect.com/science/article/pii/S1877050914011168",
      author = "Sergio Salmeron-Majadas and Olga C. Santos and Jesus G. Boticario",
      keywords = "Affective Computing, Affective States, User Modeling, Human-Computer Interaction, Keyboard, Mouse.",
      abstract = "In this paper we propose a series of indicators, which derive from user's interactions with mouse and keyboard. The goal is to evaluate their use in identifying affective states and behavior changes in an e-learning platform by means of non-intrusive and low cost methods. The approach we have followed study user's interactions regardless of the task being performed and its presentation, aiming at finding a solution applicable in any domain. In particular, mouse movements and clicks, as well as keystrokes were recorded during a math problem solving activity where users involved in the experiment had not only to score their degree of valence (i.e., pleasure versus displeasure) and arousal (i.e., high activation versus low activation) of their affective states after each problem by using the Self-Assessment-Manikin scale, but also type a description of their own feelings. By using that affective labeling, we evaluated the information provided by these different indicators processed from the original user's interactions logs. In total, we computed 42 keyboard indicators and 96 mouse indicators."
}

@inproceedings{Pentel,
      author = {Pentel, Avar},
      year = {2017},
      month = {08},
      pages = {},
      title = {Emotions and User Interactions with Keyboard and Mouse},
      doi = {10.1109/IISA.2017.8316379}
}

@inproceedings{Ghosh,
      author = {Ghosh, Surjya and Ganguly, Niloy and Mitra, Bivas and De, Pradipta},
      year = {2017},
      month = {09},
      pages = {1-12},
      title = {TapSense: combining self-report patterns and typing characteristics for smartphone based emotion detection},
      doi = {10.1145/3098279.3098564}
}

##################### related work summary citation ##################
@inproceedings{emotion_regression,
      author = {Buechel, Sven and Hahn, Udo},
      title = {Emotion Analysis as a Regression Problem — Dimensional Models and Their Implications on Emotion Representation and Metrical Evaluation},
      year = {2016},
      isbn = {9781614996712},
      publisher = {IOS Press},
      address = {NLD},
      url = {https://doi.org/10.3233/978-1-61499-672-9-1114},
      doi = {10.3233/978-1-61499-672-9-1114},
      abstract = {Emotion analysis (EA) and sentiment analysis are closely related tasks differing in the psychological phenomenon they aim to catch. We address fine-grained models for EA which treat the computation of the emotional status of narrative documents as a regression rather than a classification problem, as performed by coarse-grained approaches. We introduce Ekman's Basic Emotions (BE) and Russell and Mehrabian's Valence-Arousal-Dominance (VAD) model—two major schemes of emotion representation following opposing lines of psychological research, i.e., categorical and dimensional models— and discuss problems when BEs are used in a regression approach. We present the first natural language system thoroughly evaluated for fine-grained emotion analysis using the VAD scheme. Although we only employ simple BOW features, we reach correlation values up until r = .65 with human annotations. Furthermore, we show that the prevailing evaluation methodology relying solely on Pearson's correlation coefficient r is deficient which leads us to the introduction of a complementary error-based metric. Due to the lack of comparable (VAD-based) systems, we, finally, introduce a novel method of mapping between VAD and BE emotion representations to create a reasonable basis for comparison. This enables us to evaluate VAD output against human BE judgments and, thus, allows for a more direct comparison with existing BE-based emotion analysis systems. Even with this, admittedly, error-prone transformation step our VAD-based system achieves state-of-the-art performance in three out of six emotion categories, out-performing all existing BE-based systems but one.},
      booktitle = {Proceedings of the Twenty-Second European Conference on Artificial Intelligence},
      pages = {1114–1122},
      numpages = {9},
      location = {The Hague, The Netherlands},
      series = {ECAI'16}
}