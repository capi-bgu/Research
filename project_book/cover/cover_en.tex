\begin{titlepage}
    \begin{center}
        \vspace*{1cm}
        
        \includegraphics[width=0.1\textwidth]{figures/bgu.png}\\
        Ben-Gurion University of the Negev\\
        The Faculty of Natural Engineering\\
        The Department of \textbf{Software and Information Systems}
        
        \vspace{2cm}
        
        {\Large \textbf{CAPI - Emotion Prediction}}
        
        \vspace{1.5cm}
        
        \textbf{  Shoham Zarfti, Yuval Khoramian, Hod Twito, Ron Ziedman }
        
        \vspace{1cm}
              
        Under the supervision of \textbf{Prof. Yuval Shahar}
        
        \vspace{1cm}
  
        \begin{abstract}
          In this project, we explore the possibility of predicting a user's emotions using machine learning methods.
          In our exploration, we studied previous attempts at solving this problem through different lenses, using keyboard data, mouse data, 
          and images of the user's face. To collect the data we need, we created two pieces of software: 
          A library that can collect data on different channels, which by default collects mouse, keyboard, 
          and camera data. We also created a graphical user interface that builds on the library, runs on the user's computer, 
          and prompts the user for labels. We gave the program to a group of participants to collect their data. We then analyzed the data we 
          collected and built models that could predict the user's emotional state to varying results. As we expected, the models that rely on 
          facial data achieved the best results, models based on keyboard and mouse data achieved comparably worse results but on par with what 
          we saw in the literature. As well as using multiple feature channels, we researched the psychology of identifying emotions and decided to 
          use four types of labels, categorical or traditional emotions such as happiness, sadness, Et cetera. We also used three continuous emotion dimensions, 
          valance, arousal, and dominance, which describe a more nuanced image of the user's emotional state. We trained models 
          for various combinations of these labels and ensemble models that use multiple feature channels at once.
        \end{abstract}
  
        \vfill
        
        \textbf{June 2021}
    \end{center}
  \end{titlepage}